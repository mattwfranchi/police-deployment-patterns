{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31380b64",
   "metadata": {},
   "source": [
    "# Analysis Dataset Generation \n",
    "Used to produce results in *Detecting disparities in police deployments using dashcam data* (to appear in FAccT '23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9af78",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4caa0ee",
   "metadata": {},
   "source": [
    "### Prequisite Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe51a1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'astral'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzoneinfo\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mastral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocationInfo\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mastral\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeocoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m database, lookup\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'astral'"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "from glob import glob \n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import ast\n",
    "import datetime\n",
    "import zoneinfo\n",
    "\n",
    "from astral import LocationInfo\n",
    "from astral.geocoder import database, lookup\n",
    "import datetime\n",
    "from astral.sun import sun\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685bfe4",
   "metadata": {},
   "source": [
    "### Convenience / Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dffb119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    \"\"\"\n",
    "    print_full displays an entire pandas DataFrame x on the console. \n",
    "\n",
    "    :param x: a pandas DataFrame (or series?)\n",
    "    \"\"\" \n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    pd.set_option('display.max_columns', len(x.columns))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_columns')\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfbec47",
   "metadata": {},
   "source": [
    "### Constants & I/O Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff1de2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for all images in nexar dataset\n",
    "ALL_IMAGES_PATH = \"/share/pierson/nexar_data/raw_data/imgs\"\n",
    "# Root path for other datasets (census, crime, etc) \n",
    "DATASETS_ROOT = \"../external_datasets\"\n",
    "# Path for all model inferences for images in nexar dataset \n",
    "PREDS_PATH = \"/share/pierson/nexar_data/nexar_yolov7/\"\n",
    "\n",
    "OUTPUT_DIR = \"../output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cc9ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WGS = 'EPSG:4326'\n",
    "PROJ_CRS = 'EPSG:2263'\n",
    "NYC_COUNTY_CODES = ['005', '047', '061', '081', '085']\n",
    "sqmi2sqft = 27878400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914986d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc = lookup(\"New York\", database())\n",
    "print((\n",
    "    f\"Information for {nyc.name}/{nyc.region}\\n\"\n",
    "    f\"Timezone: {nyc.timezone}\\n\"\n",
    "    f\"Latitude: {nyc.latitude:.02f}; Longitude: {nyc.longitude:.02f}\\n\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d065254",
   "metadata": {},
   "source": [
    "### Classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9baa646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "PROX_THRESHOLD = 0.1\n",
    "\n",
    "class CrimeData:\n",
    "    def __init__(self, filename):\n",
    "        self.data = pd.read_csv(filename)\n",
    "        #print(self.data.head)\n",
    "\n",
    "        self.data['Lat_Lon'] = [ast.literal_eval(x) for x in self.data['Lat_Lon']]\n",
    "\n",
    "        self.data[\"CMPLNT_FR_DTTM\"] = pd.to_datetime(self.data[\"CMPLNT_FR_DT\"] + \" \" + self.data[\"CMPLNT_FR_TM\"]).dt.tz_localize('US/Eastern',nonexistent='shift_forward', ambiguous=True)\n",
    "    \n",
    "        #print(self.data[\"CMPLNT_FR_DTTM\"].head)\n",
    "\n",
    "        self.data[\"CMPLNT_TO_DTTM\"] = pd.to_datetime(self.data[\"CMPLNT_TO_DT\"] + \" \" + self.data[\"CMPLNT_TO_TM\"]).dt.tz_localize('US/Eastern', nonexistent='shift_forward', ambiguous=True)\n",
    "\n",
    "        self.data.drop(\"CMPLNT_FR_DT\", inplace=True, axis=1)\n",
    "        self.data.drop(\"CMPLNT_FR_TM\", inplace=True, axis=1)\n",
    "        self.data.drop(\"CMPLNT_TO_DT\", inplace=True, axis=1)\n",
    "        self.data.drop(\"CMPLNT_TO_TM\", inplace=True, axis=1)\n",
    "\n",
    "        #print(self.data[\"CMPLNT_TO_DTTM\"].head)\n",
    "\n",
    "    def filter_by_datetime(self, start_datetime, end_datetime):\n",
    "        return self.data[(self.data.CMPLNT_FR_DTTM >= start_datetime) & (self.data.CMPLNT_TO_DTTM <= end_datetime)]\n",
    "\n",
    "    def filter_by_borough(self, borough):\n",
    "        return self.data[self.data.BORO_NM == borough]\n",
    "\n",
    "    def filter_by_crime_number(self, crime_number):\n",
    "        return self.data[self.data.CMPLNT_NUM == crime_number]\n",
    "\n",
    "    def filter_by_crime_desc(self, crime_desc):\n",
    "        return self.data[self.data.OFNS_DESC == crime_desc]\n",
    "\n",
    "    def filter_by_crime_cat(self, crime_cat):\n",
    "        return self.data[self.data.LAW_CAT_CD == crime_cat]\n",
    "\n",
    "    def filter_by_age(self, age_group):\n",
    "        return self.data[self.data.SUSP_AGE_GROUP == age_group]\n",
    "\n",
    "    def filter_by_race(self, race):\n",
    "        return self.data[self.data.SUSP_RACE == race]\n",
    "\n",
    "    def return_coords(self):\n",
    "\n",
    "        print(self.data[\"Lat_Lon\"].tolist())\n",
    "        return self.data[\"Lat_Lon\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d1811",
   "metadata": {},
   "source": [
    "## Loading in External Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2fe38a",
   "metadata": {},
   "source": [
    "### Crime Data (felonies) \n",
    "Filter crime data to only include crimes within range of dataset coverage (March-November 2020). Also filter to only include felonies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d8f6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reported_felonies = CrimeData(f\"{DATASETS_ROOT}/NYPD_Complaint_Data_Historic.csv\")\\\n",
    "\n",
    "\n",
    "START_DT = datetime.datetime(2020, 3, 1, 0, 0, 0, 0, zoneinfo.ZoneInfo('US/Eastern'))\n",
    "END_DT = datetime.datetime(2020, 12, 1, 0, 0, 0, 0, zoneinfo.ZoneInfo('US/Eastern'))\n",
    "reported_felonies.data = reported_felonies.filter_by_datetime(START_DT, END_DT)\n",
    "reported_felonies.data.sort_values('CMPLNT_FR_DTTM',inplace=True)\n",
    "\n",
    "felonies_gdf = gpd.GeoDataFrame(\n",
    "    reported_felonies.data, \n",
    "    geometry= gpd.points_from_xy(\n",
    "        reported_felonies.data.Longitude, \n",
    "        reported_felonies.data.Latitude,\n",
    "        crs=\"EPSG:4326\"))\n",
    "felonies_gdf = felonies_gdf.to_crs(PROJ_CRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c180b12",
   "metadata": {},
   "source": [
    "### Load in police precinct location data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be6b3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precinct_locs = pd.read_csv(f\"{DATASETS_ROOT}/nypd_precinct_locs.csv\")\n",
    "precincts_gdf = gpd.GeoDataFrame(geometry=gpd.points_from_xy(\n",
    "    precinct_locs[\"lng\"],\n",
    "    precinct_locs[\"lat\"], \n",
    "    crs=\"EPSG:4326\"))\n",
    "precincts_gdf = precincts_gdf.to_crs(PROJ_CRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db050b",
   "metadata": {},
   "source": [
    "### Load in NYC census tract boundary data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45363e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36061000100 36061000201 36061000600 ... 36085017702 36061022700\n",
      " 36061025900]\n"
     ]
    }
   ],
   "source": [
    "nyc_tracts = gpd.read_file(f\"{DATASETS_ROOT}/NYC-tracts/\")\n",
    "nyc_tracts_proj = nyc_tracts.to_crs(PROJ_CRS)\n",
    "nyc_tracts_proj['geoid'] = pd.to_numeric(nyc_tracts_proj['geoid'])\n",
    "print(nyc_tracts_proj['geoid'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b794ab8",
   "metadata": {},
   "source": [
    "### Load in NYC census data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "639d6149",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/pandas/compat/_optional.py:141\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1206\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1142\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nyc_census \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATASETS_ROOT\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/nyc_decennialcensusdata_2010_2020_change.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m nyc_census_filtered \u001b[38;5;241m=\u001b[39m nyc_census[nyc_census[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeoType\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCT2020\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m nyc_census_demogs \u001b[38;5;241m=\u001b[39m nyc_census_filtered[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPop_20\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBCT2020\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeoID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHsp_20P\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWNH_20P\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBNH_20P\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANH_20P\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mONH_20P\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNH2pl_20P\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/pandas/io/excel/_base.py:482\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    481\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m     )\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/pandas/io/excel/_base.py:1695\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/pandas/io/excel/_openpyxl.py:556\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    544\u001b[0m     filepath_or_buffer: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[1;32m    545\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    546\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m    {storage_options}\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/pandas/compat/_optional.py:144\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "nyc_census = pd.read_excel(f\"{DATASETS_ROOT}/nyc_decennialcensusdata_2010_2020_change.xlsx\",sheet_name=1, header=3)\n",
    "nyc_census_filtered = nyc_census[nyc_census[\"GeoType\"] == \"CT2020\"]\n",
    "\n",
    "nyc_census_demogs = nyc_census_filtered[[\"Pop_20\",\"BCT2020\",\"GeoID\",\"Hsp_20P\",\"WNH_20P\",\"BNH_20P\",\"ANH_20P\",\"ONH_20P\",\"NH2pl_20P\"]]\n",
    "\n",
    "nyc_census_demogs['GeoID'] = pd.to_numeric(nyc_census_demogs['GeoID'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02eeb5d",
   "metadata": {},
   "source": [
    "Add demographic data to each tract through pandas DataFrame merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00acefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_tracts_w_demogs = nyc_tracts_proj.merge(nyc_census_demogs, left_on='geoid', right_on='GeoID', how=\"left\")\n",
    "nyc_tracts_w_demogs = nyc_tracts_w_demogs.to_crs(PROJ_CRS)\n",
    "nyc_tracts_w_demogs[\"density_tract\"] = (nyc_tracts_w_demogs[\"Pop_20\"] / nyc_tracts_w_demogs[\"geometry\"].area) * 27878400\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13630d66",
   "metadata": {},
   "source": [
    "### Load in State of New York census block group boundary data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3a94de2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ny_cbgs \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASETS_ROOT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tl_2020_36_all/tl_2020_36_bg20.shp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m ny_cbgs \u001b[38;5;241m=\u001b[39m \u001b[43mny_cbgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_crs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWGS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m nyc_cbgs \u001b[38;5;241m=\u001b[39m ny_cbgs[ny_cbgs\u001b[38;5;241m.\u001b[39mCOUNTYFP20\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m005\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m047\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m061\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m081\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m085\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[1;32m      6\u001b[0m nyc_cbgs\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/geopandas/geodataframe.py:1364\u001b[0m, in \u001b[0;36mGeoDataFrame.to_crs\u001b[0;34m(self, crs, epsg, inplace)\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1363\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m-> 1364\u001b[0m geom \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_crs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1365\u001b[0m df\u001b[38;5;241m.\u001b[39mgeometry \u001b[38;5;241m=\u001b[39m geom\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/geopandas/geoseries.py:1124\u001b[0m, in \u001b[0;36mGeoSeries.to_crs\u001b[0;34m(self, crs, epsg)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_crs\u001b[39m(\u001b[38;5;28mself\u001b[39m, crs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, epsg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a ``GeoSeries`` with all geometries transformed to a new\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;124;03m    coordinate reference system.\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \n\u001b[1;32m   1122\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GeoSeries(\n\u001b[0;32m-> 1124\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_crs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsg\u001b[49m\u001b[43m)\u001b[49m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m   1125\u001b[0m     )\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/geopandas/array.py:777\u001b[0m, in \u001b[0;36mGeometryArray.to_crs\u001b[0;34m(self, crs, epsg)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrs\u001b[38;5;241m.\u001b[39mis_exact_same(crs):\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 777\u001b[0m transformer \u001b[38;5;241m=\u001b[39m \u001b[43mTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_crs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malways_xy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m new_data \u001b[38;5;241m=\u001b[39m vectorized\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, transformer\u001b[38;5;241m.\u001b[39mtransform)\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GeometryArray(new_data, crs\u001b[38;5;241m=\u001b[39mcrs)\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/pyproj/transformer.py:600\u001b[0m, in \u001b[0;36mTransformer.from_crs\u001b[0;34m(crs_from, crs_to, always_xy, area_of_interest, authority, accuracy, allow_ballpark, force_over)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_crs\u001b[39m(\n\u001b[1;32m    543\u001b[0m     crs_from: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m     force_over: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    551\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    552\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Make a Transformer from a :obj:`pyproj.crs.CRS` or input used to create one.\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m    See:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m \n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTransformerFromCRS\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcstrencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCRS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_user_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrs_from\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcstrencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCRS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_user_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrs_to\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m            \u001b[49m\u001b[43malways_xy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malways_xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m            \u001b[49m\u001b[43marea_of_interest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marea_of_interest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m            \u001b[49m\u001b[43mauthority\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauthority\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m            \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccuracy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_ballpark\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_ballpark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_over\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_over\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/pyproj/transformer.py:326\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, transformer_maker)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProjError(\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer must be initialized using: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom_crs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom_pipeline\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    323\u001b[0m     )\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local \u001b[38;5;241m=\u001b[39m TransformerLocal()\n\u001b[0;32m--> 326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_maker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_maker \u001b[38;5;241m=\u001b[39m transformer_maker\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/pyproj/transformer.py:102\u001b[0m, in \u001b[0;36mTransformerFromCRS.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _Transformer:\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    _Transformer\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_Transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_crs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrs_from\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrs_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43malways_xy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malways_xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43marea_of_interest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marea_of_interest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauthority\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauthority\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccuracy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_ballpark\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_ballpark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_over\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_over\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mpyproj/_transformer.pyx:544\u001b[0m, in \u001b[0;36mpyproj._transformer._Transformer.from_crs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpyproj/_transformer.pyx:614\u001b[0m, in \u001b[0;36mpyproj._transformer._Transformer._init_from_crs\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpyproj/_transformer.pyx:328\u001b[0m, in \u001b[0;36mpyproj._transformer._Transformer._initialize_from_projobj\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/share/pierson/conda_virtualenvs/fpp_geospatial/lib/python3.11/site-packages/pyproj/exceptions.py:19\u001b[0m, in \u001b[0;36mProjError.clear\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         ProjError\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(error_message)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclear\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    This will clear the internal PROJ error message.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     ProjError\u001b[38;5;241m.\u001b[39minternal_proj_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ny_cbgs = gpd.read_file(f\"{DATASETS_ROOT}/tl_2020_36_all/tl_2020_36_bg20.shp\")\n",
    "ny_cbgs = ny_cbgs.to_crs(WGS)\n",
    "\n",
    "\n",
    "nyc_cbgs = ny_cbgs[ny_cbgs.COUNTYFP20.isin(NYC_COUNTY_CODES)]\n",
    "nyc_cbgs.reset_index(inplace=True)\n",
    "nyc_cbgs = nyc_cbgs.to_crs(PROJ_CRS)\n",
    "\n",
    "nyc_cbgs['GEOID20'] = pd.to_numeric(nyc_cbgs['GEOID20'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbef2d1",
   "metadata": {},
   "source": [
    "### Load in ACS Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639d1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_acs = pd.read_csv(f\"{DATASETS_ROOT}/nyc_cbgs_ethnicity_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935adaf5",
   "metadata": {},
   "source": [
    "Clean up ACS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a758ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_acs.GEOID20 = nyc_acs.GEOID20.apply(lambda x: x[9:])\n",
    "nyc_acs.GEOID20 = pd.to_numeric(nyc_acs.GEOID20)\n",
    "nyc_acs.drop(0, inplace=True)\n",
    "to_drop = [x for x in list(nyc_acs.columns) if 'annotation' in x.lower()]\n",
    "nyc_acs.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "try:\n",
    "    nyc_acs.drop(['nan_nan'], axis=1, inplace=True)\n",
    "except: \n",
    "    pass \n",
    "\n",
    "\n",
    "\n",
    "nyc_cbgs = nyc_cbgs.merge(nyc_acs, how=\"left\", on='GEOID20')\n",
    "\n",
    "\n",
    "print(nyc_cbgs.head())\n",
    "print(len(nyc_cbgs.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745d12a",
   "metadata": {},
   "source": [
    "### Load in Median Household Income Data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6eae2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "income = pd.read_csv(f\"{DATASETS_ROOT}/ACSDT5Y2020.B19013_2023-01-16T120532/ACSDT5Y2020.B19013-Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5220c6fa",
   "metadata": {},
   "source": [
    "Clean up MHI data, merge into NYC CBGs DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bc9851a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nyc_cbgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m income\u001b[38;5;241m.\u001b[39mGEO_ID \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(income\u001b[38;5;241m.\u001b[39mGEO_ID)\n\u001b[1;32m      5\u001b[0m income\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m nyc_cbgs \u001b[38;5;241m=\u001b[39m \u001b[43mnyc_cbgs\u001b[49m\u001b[38;5;241m.\u001b[39mmerge(income, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEOID20\u001b[39m\u001b[38;5;124m\"\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEO_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m cols_to_rename \u001b[38;5;241m=\u001b[39m { \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB19013_001E\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian_household_income\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m nyc_cbgs_proj\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39mcols_to_rename, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nyc_cbgs' is not defined"
     ]
    }
   ],
   "source": [
    "income.drop(0,axis=0, inplace=True)\n",
    "income.drop([\"B19013_001EA\", \"B19013_001M\", \"B19013_001MA\",\"Unnamed: 6\"], axis=1, inplace=True)\n",
    "income.GEO_ID = income.GEO_ID.apply(lambda x: x[9:])\n",
    "income.GEO_ID = pd.to_numeric(income.GEO_ID)\n",
    "income.drop('NAME', axis=1, inplace=True)\n",
    "nyc_cbgs = nyc_cbgs.merge(income, how=\"left\", left_on=\"GEOID20\", right_on=\"GEO_ID\")\n",
    "\n",
    "cols_to_rename = { \n",
    "    \"B19013_001E\": \"median_household_income\"\n",
    "}\n",
    "nyc_cbgs.rename(columns=cols_to_rename, inplace=True)\n",
    "print(nyc_cbgs.columns)\n",
    "\n",
    "assert ((income[\"B19013_001E\"] == '-').sum()) == ((nyc_cbgs[\"median_household_income\"] == '-').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ea570",
   "metadata": {},
   "source": [
    "### Calculate CBG density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08322aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_cbgs[\"density_cbg\"] = (nyc_cbgs[\"Estimate_Total\"] / nyc_cbgs[\"geometry\"].area) * sqmi2sqft\n",
    "nyc_cbgs[\"density_cbg\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cd3a7e",
   "metadata": {},
   "source": [
    "### Calculate CBG centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_cbgs['centroid'] = nyc_cbgs.geometry.centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a4fb2e",
   "metadata": {},
   "source": [
    "### Merging census tract demographic data into CBG DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "bounds = nyc_cbgs.geometry\n",
    "print(nyc_cbgs.columns)\n",
    "nyc_cbgs = nyc_cbgs.set_geometry(nyc_cbgs['centroid']).sjoin(nyc_tracts_w_demogs, how='left', lsuffix=\"cbg\", rsuffix=\"ct\", predicate='within')\n",
    "nyc_cbgs.set_geometry(bounds,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408c6bea",
   "metadata": {},
   "source": [
    "### Final Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c937fa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nyc_cbgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m MoE_columns \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43mnyc_cbgs\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMargin of Error\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[1;32m      2\u001b[0m est_columns \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(nyc_cbgs\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstimate\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[1;32m      3\u001b[0m other_numeric_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_household_income\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALAND20\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAWATER20\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nyc_cbgs' is not defined"
     ]
    }
   ],
   "source": [
    "MoE_columns = [x for x in list(nyc_cbgs.columns) if 'Margin of Error' in x]\n",
    "est_columns = [x for x in list(nyc_cbgs.columns) if 'Estimate' in x]\n",
    "other_numeric_cols = ['median_household_income','ALAND20','AWATER20']\n",
    "\n",
    "for col in MoE_columns + est_columns: \n",
    "    nyc_cbgs[col] = nyc_cbgs[col].astype(str).str.replace('-','-1')\n",
    "    nyc_cbgs[col] = nyc_cbgs[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004cf339",
   "metadata": {},
   "source": [
    "## Loading in internal data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94cef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_filenames = glob(\"/share/pierson/nexar_data/raw_data/metadata_split_filtered/anl/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf72899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = [pd.read_csv(x, engine='pyarrow') for x in md_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3840d4f",
   "metadata": {},
   "source": [
    "## Analysis CSV Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enriched_csv(md_tuple, nyc_cbgs):\n",
    "    \n",
    "    m_idx, md = md_tuple\n",
    "    \n",
    "    if len(md.index) == 0: \n",
    "        return \n",
    "    \n",
    "    print(md_files[m_idx])\n",
    "    \n",
    "    if \"processed\" in md_files[m_idx]:\n",
    "        # Thursdays logic\n",
    "        ALL_IMAGES_PATHS = [\"/share/pierson/nexar_data/raw_data/imgs/thursdays/dir_0\", \n",
    "                            \"/share/pierson/nexar_data/raw_data/imgs/thursdays/dir_1\",\n",
    "                            \"/share/pierson/nexar_data/raw_data/imgs/thursdays/dir_2\",\n",
    "                            \"/share/pierson/nexar_data/raw_data/imgs/thursdays/dir_3\"]\n",
    "        PREDS_PATHS = glob(\"/share/pierson/nexar_data/nexar_yolov7/entire_dataset_inferences/dir_*/exp/labels\")\n",
    "        MD_PATHS = glob(\"/share/pierson/nexar_data/raw_data/metadata_split_filtered/anl/processed_*.csv\")\n",
    "        \n",
    "        \n",
    "\n",
    "    else:\n",
    "        # Oct-Nov logic\n",
    "        ALL_IMAGES_PATHS = [f\"/share/pierson/nexar_data/raw_data/imgs/oct_15-nov-15/{os.path.splitext(os.path.basename(md_files[m_idx]))[0]}\"]\n",
    "        PREDS_PATHS = [f\"/share/pierson/nexar_data/nexar_yolov7/entire_dataset_inferences/{os.path.splitext(os.path.basename(md_files[m_idx]))[0]}/exp/labels\"]\n",
    "        MD_PATHS = [f\"/share/pierson/nexar_data/raw_data/metadata_split_filtered/anl/{os.path.basename(md_files[m_idx])}\"]\n",
    "        \n",
    "    print(ALL_IMAGES_PATHS)\n",
    "    \n",
    "    #all_images = pd.DataFrame()\n",
    "    #for path in ALL_IMAGES_PATHS: \n",
    "        #imgs = {'image_ref': glob(f\"{path}/*.jpg\")}\n",
    "        #all_images = pd.concat([all_images, pd.DataFrame(data=imgs)])\n",
    "    #all_images[\"base\"] = all_images.apply(lambda x: os.path.splitext(os.path.basename(x)[0]))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    all_preds = pd.DataFrame()\n",
    "    for path in PREDS_PATHS:\n",
    "        preds = {'image_ref': glob(f\"{path}/*.txt\")}\n",
    "        all_preds = pd.concat([all_preds, pd.DataFrame(data=preds)], axis=0, ignore_index=True)\n",
    "        \n",
    "        \n",
    "    yhat = []\n",
    "\n",
    "    for idx, row in all_preds.iterrows():\n",
    "        #base_filename = row[\"image_ref\"]\n",
    "\n",
    "        # read label y_hat\n",
    "\n",
    "        full_label_path = row[\"image_ref\"]\n",
    "        if os.path.exists(full_label_path):\n",
    "            d = pd.read_csv(full_label_path, \n",
    "                            sep=' ', \n",
    "                            names=['class_type', 'dummy1', 'dummy2', 'dummy3', 'dummy4', 'conf'])\n",
    "            # sanity checks. \n",
    "            assert d['class_type'].map(lambda x:x in [0, 1]).all()\n",
    "            assert d['conf'].max() <= 1\n",
    "            assert d['conf'].min() >= 0\n",
    "            d = d.loc[d['class_type'] == 1] # only interested in labels for police cars. \n",
    "            if len(d) == 0:\n",
    "                yhat.append(0) # if no labels for police cars, yhat is 0. \n",
    "            else:\n",
    "                yhat.append(d['conf'].max()) # otherwise take max confidence. \n",
    "        else:\n",
    "            yhat.append(0)\n",
    "        \n",
    "\n",
    "    yhat = np.array(yhat)\n",
    "    print(yhat.size, 'have detections')\n",
    "    all_preds[\"conf\"] = yhat \n",
    "\n",
    "    all_preds[\"base\"] = all_preds[\"image_ref\"].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "    \n",
    "    md[\"base\"] = md[\"image_ref\"].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "    \n",
    "    md.set_index(md[\"base\"], inplace=True)\n",
    "    all_preds.set_index(all_preds[\"base\"], inplace=True)\n",
    "    all_preds[\"has_prediction\"] = 1\n",
    "    all_preds.drop([\"base\",\"image_ref\"], axis=1, inplace=True)\n",
    "    \n",
    "    intersection = pd.merge(md, all_preds, how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    print(len(intersection.index)) \n",
    "    \n",
    "    assert len(md.index) == len(intersection.index)\n",
    "    \n",
    "    print(intersection.head())\n",
    "    \n",
    "    md = intersection\n",
    "    \n",
    "    \n",
    "    \n",
    "    # time_and_date\n",
    "    md[\"time_and_date_of_imafge\"] = pd.to_datetime(md[\"timestamp\"], unit='ms', utc=True)\n",
    "    md[\"time_and_date_of_image\"] = md[\"time_and_date_of_image\"].dt.tz_convert('US/Eastern')\n",
    "    \n",
    "    # extended temporal metrics\n",
    "    md[\"hour\"] = md[\"time_and_date_of_image\"].apply(lambda x: x.hour)\n",
    "    md[\"day_of_week\"] = md[\"time_and_date_of_image\"].apply(lambda x: x.weekday())\n",
    "    md[\"day_of_month\"] = md[\"time_and_date_of_image\"].apply(lambda x: x.day)\n",
    "    md[\"month\"] = md[\"time_and_date_of_image\"].apply(lambda x: x.month)\n",
    "    md[\"day_of_week\"].describe()\n",
    "    md[\"day_of_month\"].describe()\n",
    "    md[\"weekend\"] = md[\"day_of_week\"] > 4\n",
    "    md[\"weekend\"] = md[\"weekend\"].apply(lambda x: 0 if x is False else 1)\n",
    "    md[\"phase\"] = md[\"time_and_date_of_image\"] > datetime.datetime(2020,9,1,0,0,0, tzinfo=zoneinfo.ZoneInfo(\"US/Eastern\"))\n",
    "    md[\"phase\"] = md[\"phase\"].apply(lambda x: 0 if x is False else 1)\n",
    "    \n",
    "    # daytime calculation\n",
    "    batch = md.copy(deep=True)\n",
    "    # Set index of batch to the timestamp column\n",
    "    batch = batch.set_index('time_and_date_of_image')\n",
    "\n",
    "    # Get list of all days occuring in subset \n",
    "    days = batch.index \n",
    "    days = pd.to_datetime(days).date\n",
    "    days = np.unique(days)\n",
    "\n",
    "    # Generate sunrise and sunset times for each day in list\n",
    "    sunrises = np.empty(0,dtype=datetime.datetime)\n",
    "    sunsets = np.empty(0,dtype=datetime.datetime)\n",
    "    for day in days: \n",
    "        s = sun(nyc.observer, date=day, tzinfo=nyc.timezone)\n",
    "\n",
    "        sunrises = np.append(sunrises, s[\"sunrise\"])\n",
    "\n",
    "        sunsets = np.append(sunsets, s[\"sunset\"])\n",
    "\n",
    "\n",
    "\n",
    "    # Compile sunrise, sunset, and dates into dataframe \n",
    "    sun_data = pd.DataFrame()\n",
    "    sun_data[\"day\"] = pd.to_datetime(days)\n",
    "    sun_data[\"sunrise\"] = sunrises \n",
    "    sun_data[\"sunset\"] = sunsets \n",
    "\n",
    "    # Set index to date, convert sunset and sunrise to datetime\n",
    "    sun_data = sun_data.set_index(\"day\")\n",
    "    sun_data[\"sunrise\"] = pd.to_datetime(sun_data[\"sunrise\"])\n",
    "    sun_data[\"sunset\"] = pd.to_datetime(sun_data[\"sunset\"])\n",
    "\n",
    "    # Generate day column for each batch \n",
    "    batch[\"day\"] = pd.to_datetime(batch.index.date)\n",
    "    #print(batch[\"day\"])\n",
    "    # Generate sunrise column for each batch \n",
    "    # Generate sunset column for each batch \n",
    "    batch = batch.merge(sun_data, left_on='day' ,right_index=True, how='left')\n",
    "    batch.drop(\"day\", axis=1, inplace=True)\n",
    "\n",
    "    batch[\"nighttime\"] = (batch.index < batch[\"sunrise\"]) | (batch.index > batch[\"sunset\"])\n",
    "\n",
    "    daytime_imgs = batch[batch[\"nighttime\"] == False]\n",
    "    nighttime_imgs = batch[batch[\"nighttime\"] == True]\n",
    "\n",
    "    assert len(daytime_imgs.index) + len(nighttime_imgs.index) == len(batch.index)\n",
    "\n",
    "    md[\"nighttime\"] = batch[\"nighttime\"].values\n",
    "    md[\"nighttime\"] = md[\"nighttime\"].apply(lambda x: 0 if x is False else 1)\n",
    "    \n",
    "    # Nearest_Crime\n",
    "    md = gpd.GeoDataFrame(md, geometry=gpd.points_from_xy(md.lng, md.lat, crs=\"EPSG:4326\"))\n",
    "    md = md.to_crs(\"EPSG:2263\")   \n",
    "    \n",
    "    point_of_nearest_crimes = []\n",
    "    desc_of_nearest_crimes = []\n",
    "    time_of_nearest_crimes = []\n",
    "\n",
    "    metrics = {\n",
    "        \"nearest_crime_1hr\": 1,\n",
    "        \"nearest_crime_3hr\": 3,\n",
    "        \"nearest_crime_6hr\": 6\n",
    "    }\n",
    "\n",
    "    for name, td in metrics.items(): \n",
    "\n",
    "        point_of_nearest_crimes = []\n",
    "        desc_of_nearest_crimes = []\n",
    "        time_of_nearest_crimes = []\n",
    "\n",
    "        for idx_s, row in md.iterrows(): \n",
    "            felonies_soonafter = felonies_gdf[(felonies_gdf[\"CMPLNT_FR_DTTM\"] >= row[\"time_and_date_of_image\"]) & (felonies_gdf[\"CMPLNT_FR_DTTM\"] <= row[\"time_and_date_of_image\"] + datetime.timedelta(hours=td))]\n",
    "            multipoint = felonies_soonafter.geometry.unary_union\n",
    "            try:\n",
    "                queried_geom, nearest_geom = nearest_points(row.geometry, multipoint)\n",
    "                nearest = felonies_soonafter.geometry == nearest_points(row.geometry, multipoint)[1]\n",
    "                nearest_crime = felonies_soonafter[nearest]\n",
    "                nearest_crime = nearest_crime.iloc[0]\n",
    "\n",
    "                point_of_nearest_crimes.append(nearest_crime.geometry)\n",
    "                desc_of_nearest_crimes.append(nearest_crime.OFNS_DESC)\n",
    "                time_of_nearest_crimes.append(nearest_crime.CMPLNT_FR_DTTM)\n",
    "                \n",
    "            except Exception as e: \n",
    "                #print(e)\n",
    "                point_of_nearest_crimes.append(None)\n",
    "                desc_of_nearest_crimes.append(None)\n",
    "                time_of_nearest_crimes.append(None)\n",
    "\n",
    "\n",
    "        print(len(point_of_nearest_crimes))\n",
    "        md[f\"point_of_{name}\"] = point_of_nearest_crimes \n",
    "        md[f\"desc_of_{name}\"] = desc_of_nearest_crimes\n",
    "        md[f\"time_of_{name}\"] = time_of_nearest_crimes\n",
    "\n",
    "\n",
    "        points_of_nearest_crime = gpd.GeoSeries(md[f\"point_of_{name}\"], crs=\"EPSG:2263\")\n",
    "\n",
    "        distances_from_nearest_crime = points_of_nearest_crime.distance(md.geometry)\n",
    "\n",
    "        print(distances_from_nearest_crime.describe())\n",
    "\n",
    "        md[f\"distance_from_{name}\"] = distances_from_nearest_crime\n",
    "\n",
    "\n",
    "    \n",
    "    # Nearest Police Station \n",
    "    nearest_station = gpd.sjoin_nearest(md, precincts_gdf, how=\"left\", distance_col=\"distance\")\n",
    "    print(nearest_station[\"distance\"].describe())\n",
    "    md[\"distance_from_nearest_police_station\"] = nearest_station[\"distance\"]\n",
    "    \n",
    "    \n",
    "    # Census\n",
    "    md = gpd.sjoin(md, nyc_cbgs, how='left')\n",
    "    \n",
    "    #Filter\n",
    "    #md.drop('geometry', axis=1, inplace=True)\n",
    "    \n",
    "    # Summary\n",
    "    print(md.columns)\n",
    "    try:\n",
    "        md.drop('base.1', inplace=True, axis=1)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        \n",
    "    md.to_csv(f\"/share/pierson/nexar_data/acs_enriched_with_nta/{os.path.basename(md_files[m_idx])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a42bf7d",
   "metadata": {},
   "source": [
    "### Distributed processing [this actually generates the dataset, assuming all prior steps have been run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ad72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool()                         # Create a multiprocessing Pool\n",
    "pool.map(enriched_csv, enumerate(mds), nyc_cbgs)  # process data_inputs iterable with pool"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fpp_geospatial] *",
   "language": "python",
   "name": "conda-env-fpp_geospatial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
